{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNIST digits classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mnist_sample.png\" style=\"width:30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using TF 1.2.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "print(\"We're using TF\", tf.__version__)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import grading\n",
    "\n",
    "import matplotlib_utils\n",
    "from importlib import reload\n",
    "reload(matplotlib_utils)\n",
    "\n",
    "import grading_utils\n",
    "reload(grading_utils)\n",
    "\n",
    "import keras_utils\n",
    "from keras_utils import reset_tf_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in your Coursera token and email\n",
    "To successfully submit your answers to our grader, please fill in your Coursera submission token and email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader = grading.Grader(assignment_key=\"XtD7ho3TEeiHQBLWejjYAA\", \n",
    "                        all_parts=[\"9XaAS\", \"vmogZ\", \"RMv95\", \"i8bgs\", \"rE763\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"u2bQdurl8iEMdZ1J\"\n",
    "COURSERA_EMAIL = \"emanuelfontelles@fisica.ufc.br\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the data\n",
    "\n",
    "In this task we have 50000 28x28 images of digits from 0 to 9.\n",
    "We will train a classifier on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessed_mnist\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocessed_mnist.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEJhJREFUeJzt3XuMXOV9xvHvg6+xMcEbg+uAAwacAIHGNCsDwgVSGgKo\nEqAIiJWkDiFxmnAprdNC6QUakcqJEhAhFNUUB0O534TVEiKwUi4iOCwEjLmDMcHGXmMcMBjiy/rX\nP+Y4XczOu+u5ndl9n4802tnzO2fOzwPPnpl5z5xXEYGZ5Wenshsws3I4/GaZcvjNMuXwm2XK4TfL\nlMNvlimHP0OS/lfSN1q9rbUXh3+Qk7Rc0p+X3UeKpKMlbZX0bq/brLL7yt3wshuwbLweEXuW3YT9\nPx/5hyBJ4yX9t6Q3JP2uuL998PaV9GtJ6yXdJamj1/aHSXpY0luSnpR0dGv/BdYKDv/QtBPwM2Av\n4BPA+8BPt1vnL4GvA5OALcBPACTtAfwPcDHQAXwXuF3SbtvvRNKM4g9EtduMXqvvLqlb0iuSLpU0\ntrH/ZNtRDv8QFBFvRsTtEfFeRLwDfB84arvVrouIpRGxAfhn4FRJw4CvAHdHxN0RsTUi7gW6gBP6\n2M9DEbFr4vZQsepzwDQqf2j+DPgscElT/vE2YA7/ECRpjKT/kPSqpPXAA8CuRbi3ea3X/VeBEcAE\nKq8WTul9BAdmUAluTSJidUQ8U/wxeQX4e+CLtT6eNYY/8Bua5gCfAg6NiNWSpgG/AdRrncm97n8C\n2AyspfJH4bqI+GZ/O5H0p8DPE6scHxEP9rE88IGndA7/0DBC0uhev4+n8j7/reKDvAv72OYrkq4F\nlgPfA26LiB5J/wU8KukLwH1UXhEcBrwUESt6P0AR7J37a07S54BlwG+BPYEfAHft2D/RGs1/fYeG\nu6mEfdttV+AjVI7kjwD39LHNdcA1wGpgNHAOQES8BpwIXAC8QeWVwN9R3/8rhwAPAxuKn0u27c/K\nI1/MwyxPPvKbZcrhN8uUw2+WKYffLFMtHeobqVExGp/VadYsv2cDm2Kj+l+zzvBLOg64DBgG/GdE\nzE2tP5qxHKpj6tmlmSUsjkUDXrfml/3FqaJXAMcDBwIzJR1Y6+OZWWvV855/OpWzvpZFxCbgJion\nh5jZIFBP+Pfgg18OWVEs+wBJsyV1SerazMY6dmdmjdT0T/sjYl5EdEZE5whGNXt3ZjZA9YR/JR/8\nZtiexTIzGwTqCf+jwFRJUySNBL4ELGxMW2bWbDUP9UXEFklnAb+gMtQ3PyKeblhnZtZUdY3zR8Td\nVL5OamaDjE/vNcuUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mm\nHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+W\nKYffLFMOv1mmHH6zTNU1S6+1Pw1P/ycettuEpu7/+e/uXbXWM2Zrctu99l2TrI/5jpL11ZeMrFp7\nvPPm5LZrezYk64feOidZ3+9vH0nW20Fd4Ze0HHgH6AG2RERnI5oys+ZrxJH/cxGxtgGPY2Yt5Pf8\nZpmqN/wB3CfpMUmz+1pB0mxJXZK6NrOxzt2ZWaPU+7J/RkSslLQ7cK+k5yLigd4rRMQ8YB7ALuqI\nOvdnZg1S15E/IlYWP9cAdwLTG9GUmTVfzeGXNFbSuG33gWOBpY1qzMyaq56X/ROBOyVte5wbIuKe\nhnQ1xAw7YGqyHqNGJOuvH7Vrsv7+YdXHpDs+mh6vfvAz6fHuMv38vXHJ+g9+elyyvvjgG6rWXtn8\nfnLbud2fT9Y//uDgfwdbc/gjYhnwmQb2YmYt5KE+s0w5/GaZcvjNMuXwm2XK4TfLlL/S2wA9R/9J\nsn7JNVck658cUf2rp0PZ5uhJ1v/l8q8l68M3pIfbDr/1rKq1cSu3JLcdtTY9FDima3GyPhj4yG+W\nKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrj/A0w6vnXk/XHfj85Wf/kiO5GttNQc1Ydlqwvezd9\n6e9r9r2tau3trelx+ok/eThZb6bB/4Xd/vnIb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlShGt\nG9HcRR1xqI5p2f7axbrTD0/W1x+Xvrz2sCU7J+tPfufyHe5pm4vX/nGy/uhR6XH8nrfeTtbj8OoX\neF5+TnJTpsx8Mr2CfcjiWMT6WJeeu7zgI79Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimP87eB\nYRM+lqz3vLkuWX/lhupj9U8fOT+57fR/OztZ3/2K8r5TbzuuoeP8kuZLWiNpaa9lHZLulfRi8XN8\nPQ2bWesN5GX/NcBx2y07H1gUEVOBRcXvZjaI9Bv+iHgA2P5154nAguL+AuCkBvdlZk1W6zX8JkbE\nquL+amBitRUlzQZmA4xmTI27M7NGq/vT/qh8Ylj1U8OImBcRnRHROYJR9e7OzBqk1vB3S5oEUPxc\n07iWzKwVag3/QmBWcX8WcFdj2jGzVun3Pb+kG4GjgQmSVgAXAnOBWySdAbwKnNrMJoe6nrVv1rX9\n5vUja972019+Jll/48ph6QfY2lPzvq1c/YY/ImZWKflsHbNBzKf3mmXK4TfLlMNvlimH3yxTDr9Z\npjxF9xBwwHkvVK2dfnB6UOZney1K1o865cxkfdzNjyTr1r585DfLlMNvlimH3yxTDr9Zphx+s0w5\n/GaZcvjNMuVx/iEgNU32m98+ILntbxe+n6yff/G1yfo/nHpysh6/+WjV2uTv/yq5LS28rHyOfOQ3\ny5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLlKbozt+7rhyfr11/4o2R9yvDRNe/709eelaxPvWpV\nsr5l2fKa9z1UNXSKbjMbmhx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimP81tSHDEtWd9l7opk/cZ9\nflHzvvf/5TeS9U/9a/XrGAD0vLis5n0PVg0d55c0X9IaSUt7LbtI0kpJTxS3E+pp2MxabyAv+68B\njutj+aURMa243d3Ytsys2foNf0Q8AKxrQS9m1kL1fOB3tqQlxduC8dVWkjRbUpekrs1srGN3ZtZI\ntYb/SmAfYBqwCvhxtRUjYl5EdEZE5whG1bg7M2u0msIfEd0R0RMRW4GrgOmNbcvMmq2m8Eua1OvX\nk4Gl1dY1s/bU7zi/pBuBo4EJQDdwYfH7NCCA5cC3IiL95Ws8zj8UDZu4e7L++mn7Va0tPu+y5LY7\n9XNs+vIrxybrb894M1kfinZknL/fSTsiYmYfi6/e4a7MrK349F6zTDn8Zply+M0y5fCbZcrhN8uU\nv9JrpbllRXqK7jEamay/F5uS9b84+9zqj33n4uS2g5Uv3W1m/XL4zTLl8JtlyuE3y5TDb5Yph98s\nUw6/Wab6/Vaf5W3rjPSlu18+JT1F90HTllet9TeO35/L1x2SrI+5q6uuxx/qfOQ3y5TDb5Yph98s\nUw6/WaYcfrNMOfxmmXL4zTLlcf4hTp0HJesvnJMea7/qiAXJ+pGj09+pr8fG2JysP7JuSvoBtvZ7\nNfms+chvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2Wq33F+SZOBa4GJVKbknhcRl0nqAG4G9qYy\nTfepEfG75rWar+FT9krWXz7941VrF512U3LbL+68tqaeGuGC7s5k/f7LDkvWxy9IX/ff0gZy5N8C\nzImIA4HDgDMlHQicDyyKiKnAouJ3Mxsk+g1/RKyKiMeL++8AzwJ7ACcC207/WgCc1Kwmzazxdug9\nv6S9gUOAxcDEiNh2/uRqKm8LzGyQGHD4Je0M3A6cGxHre9eiMuFfn5P+SZotqUtS12Y21tWsmTXO\ngMIvaQSV4F8fEXcUi7slTSrqk4A1fW0bEfMiojMiOkcwqhE9m1kD9Bt+SQKuBp6NiEt6lRYCs4r7\ns4C7Gt+emTXLQL7SewTwVeApSU8Uyy4A5gK3SDoDeBU4tTktDn7D9/5Esv72Zycl66d9755k/a92\nvSNZb6Y5q9LDcb/69+rDeR3X/Dq57fitHsprpn7DHxEPAdXm+z6mse2YWav4DD+zTDn8Zply+M0y\n5fCbZcrhN8uUw2+WKV+6e4CGT/qjqrV188cmt/32lPuT9ZnjumvqqRHOWjkjWX/8yvQU3RNuW5qs\nd7zjsfp25SO/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5apbMb5N30hfZnoTX+zLlm/YL+7q9aO\n/ciGmnpqlO6e96vWjlw4J7nt/v/0XLLe8VZ6nH5rsmrtzEd+s0w5/GaZcvjNMuXwm2XK4TfLlMNv\nlimH3yxT2YzzLz8p/XfuhYNvbdq+r3hr32T9svuPTdbVU+3K6RX7X/xK1drU7sXJbXuSVRvKfOQ3\ny5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTKliEivIE0GrgUmAgHMi4jLJF0EfBN4o1j1goio/qV3\nYBd1xKHyrN5mzbI4FrE+1qVPDCkM5CSfLcCciHhc0jjgMUn3FrVLI+JHtTZqZuXpN/wRsQpYVdx/\nR9KzwB7NbszMmmuH3vNL2hs4BNh2zujZkpZImi9pfJVtZkvqktS1mY11NWtmjTPg8EvaGbgdODci\n1gNXAvsA06i8MvhxX9tFxLyI6IyIzhGMakDLZtYIAwq/pBFUgn99RNwBEBHdEdETEVuBq4DpzWvT\nzBqt3/BLEnA18GxEXNJr+aReq50MpKdrNbO2MpBP+48Avgo8JemJYtkFwExJ06gM/y0HvtWUDs2s\nKQbyaf9DQF/jhskxfTNrbz7DzyxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Z\nphx+s0w5/GaZcvjNMuXwm2Wq30t3N3Rn0hvAq70WTQDWtqyBHdOuvbVrX+DeatXI3vaKiN0GsmJL\nw/+hnUtdEdFZWgMJ7dpbu/YF7q1WZfXml/1mmXL4zTJVdvjnlbz/lHbtrV37AvdWq1J6K/U9v5mV\np+wjv5mVxOE3y1Qp4Zd0nKTnJb0k6fwyeqhG0nJJT0l6QlJXyb3Ml7RG0tJeyzok3SvpxeJnn3Mk\nltTbRZJWFs/dE5JOKKm3yZJ+KekZSU9L+utieanPXaKvUp63lr/nlzQMeAH4PLACeBSYGRHPtLSR\nKiQtBzojovQTQiQdCbwLXBsRBxXLfgisi4i5xR/O8RFxXpv0dhHwbtnTthezSU3qPa08cBLwNUp8\n7hJ9nUoJz1sZR/7pwEsRsSwiNgE3ASeW0Efbi4gHgHXbLT4RWFDcX0Dlf56Wq9JbW4iIVRHxeHH/\nHWDbtPKlPneJvkpRRvj3AF7r9fsKSnwC+hDAfZIekzS77Gb6MDEiVhX3VwMTy2ymD/1O295K200r\n3zbPXS3T3TeaP/D7sBkRMQ04HjizeHnblqLynq2dxmoHNG17q/QxrfwflPnc1TrdfaOVEf6VwORe\nv+9ZLGsLEbGy+LkGuJP2m3q8e9sMycXPNSX38wftNG17X9PK0wbPXTtNd19G+B8FpkqaImkk8CVg\nYQl9fIikscUHMUgaCxxL+009vhCYVdyfBdxVYi8f0C7TtlebVp6Sn7u2m+4+Ilp+A06g8on/y8A/\nltFDlb72AZ4sbk+X3RtwI5WXgZupfDZyBvAxYBHwInAf0NFGvV0HPAUsoRK0SSX1NoPKS/olwBPF\n7YSyn7tEX6U8bz691yxT/sDPLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8vU/wHB2k2an6KQXAAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb81c9b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.title(\"Label=\"+str(y_train[0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [shape (50000, 28, 28)] sample patch:\n",
      " [[ 0.          0.29803922  0.96470588  0.98823529  0.43921569]\n",
      " [ 0.          0.33333333  0.98823529  0.90196078  0.09803922]\n",
      " [ 0.          0.33333333  0.98823529  0.8745098   0.        ]\n",
      " [ 0.          0.33333333  0.98823529  0.56862745  0.        ]\n",
      " [ 0.          0.3372549   0.99215686  0.88235294  0.        ]]\n",
      "A closeup of a sample patch:\n"
     ]
    }
   ],
   "source": [
    "# X contains rgb values divided by 255\n",
    "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
    "print(\"A closeup of a sample patch:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb81bdfda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the whole sample:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb6a4bd320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train [shape (50000,)] 10 samples:\n",
      " [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
    "plt.show()\n",
    "print(\"And the whole sample:\")\n",
    "plt.imshow(X_train[1], cmap=\"Greys\")\n",
    "plt.show()\n",
    "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model\n",
    "\n",
    "Your task is to train a linear classifier $\\vec{x} \\rightarrow y$ with SGD using TensorFlow.\n",
    "\n",
    "You will need to calculate a logit (a linear transformation) $z_k$ for each class: \n",
    "$$z_k = \\vec{x} \\cdot \\vec{w_k} + b_k \\quad k = 0..9$$\n",
    "\n",
    "And transform logits $z_k$ to valid probabilities $p_k$ with softmax: \n",
    "$$p_k = \\frac{e^{z_k}}{\\sum_{i=0}^{9}{e^{z_i}}} \\quad k = 0..9$$\n",
    "\n",
    "We will use a cross-entropy loss to train our multi-class classifier:\n",
    "$$\\text{cross-entropy}(y, p) = -\\sum_{k=0}^{9}{\\log(p_k)[y = k]}$$ \n",
    "\n",
    "where \n",
    "$$\n",
    "[x]=\\begin{cases}\n",
    "       1, \\quad \\text{if $x$ is true} \\\\\n",
    "       0, \\quad \\text{otherwise}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Cross-entropy minimization pushes $p_k$ close to 1 when $y = k$, which is what we want.\n",
    "\n",
    "Here's the plan:\n",
    "* Flatten the images (28x28 -> 784) with `X_train.reshape((X_train.shape[0], -1))` to simplify our linear model implementation\n",
    "* Use a matrix placeholder for flattened `X_train`\n",
    "* Convert `y_train` to one-hot encoded vectors that are needed for cross-entropy\n",
    "* Use a shared variable `W` for all weights (a column $\\vec{w_k}$ per class) and `b` for all biases.\n",
    "* Aim for ~0.93 validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
    "print(X_train_flat.shape)\n",
    "\n",
    "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
    "print(X_val_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]] [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
    "y_val_oh = keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "print(y_train_oh.shape)\n",
    "print(y_train_oh[:3], y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this again if you remake your graph\n",
    "s = reset_tf_session()\n",
    "\n",
    "# Model parameters: W and b \n",
    "W = tf.get_variable(\"W\", shape=(784, 10), dtype=tf.float32, trainable=True) ### tf.get_variable(...) with shape[0] = 784\n",
    "b = tf.get_variable(\"b\", shape=(10,), dtype=tf.float32) ### tf.get_variable(...)\n",
    "\n",
    "# Placeholders for the input data\n",
    "input_X = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "input_y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "# Compute predictions\n",
    "logits = ### YOUR CODE HERE ### logits for input_X, resulting shape should be [input_X.shape[0], 10]\n",
    "probas = ### YOUR CODE HERE ### apply tf.nn.softmax to logits\n",
    "classes = ### YOUR CODE HERE ### apply tf.argmax to find a class index with highest probability\n",
    "\n",
    "# Loss should be a scalar number: average loss over all the objects with tf.reduce_mean().\n",
    "# Use tf.nn.softmax_cross_entropy_with_logits on top of one-hot encoded input_y and logits.\n",
    "# It is identical to calculating cross-entropy on top of probas, but is more numerically friendly (read the docs).\n",
    "loss = ### YOUR CODE HERE ### cross-entropy loss\n",
    "\n",
    "# Use a default tf.train.AdamOptimizer to get an SGD step\n",
    "step = ### YOUR CODE HERE ### optimizer step that minimizes the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1_size = 100\n",
    "hidden_2_size = 50\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    input_x = tf.placeholder(tf.float32,shape= [None,28,28])\n",
    "    input_y = tf.placeholder(tf.int32,shape=[None,])\n",
    "    \n",
    "    x = tf.reshape(input_x,[-1,28*28])\n",
    "    y = tf.one_hot(input_y,depth=10,axis=-1)\n",
    "    \n",
    "    w1 = tf.Variable(tf.truncated_normal([28*28,hidden_1_size],stddev=0.1),name='weight_1')\n",
    "    b1 = tf.Variable(tf.zeros([hidden_1_size]),name='bias_1')\n",
    "    w2 = tf.Variable(tf.truncated_normal([hidden_1_size,hidden_2_size],stddev=0.1),name='weight_2')\n",
    "    b2 = tf.Variable(tf.zeros([hidden_2_size]),name='bias_1')\n",
    "    w3 = tf.Variable(tf.truncated_normal([hidden_2_size,10],stddev=0.1),name='weight_3')\n",
    "    b3 = tf.Variable(tf.zeros([10,]),name = 'bias_3')\n",
    "\n",
    "    \n",
    "    fc1 = tf.nn.relu(tf.nn.bias_add(tf.matmul(x,w1),b1))\n",
    "    fc2 = tf.nn.sigmoid(tf.nn.bias_add(tf.matmul(fc1,w2),b2))\n",
    "    \n",
    "    logits = tf.nn.bias_add(tf.matmul(fc2,w3),b3)\n",
    "    probs = tf.nn.softmax(logits)\n",
    "    preds = tf.argmax(logits,axis=1)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  train_acc  0.15636  val_acc  0.1477\n",
      "epoch  1  train_acc  0.20104  val_acc  0.1943\n",
      "epoch  2  train_acc  0.2737  val_acc  0.269\n",
      "epoch  3  train_acc  0.31632  val_acc  0.3136\n",
      "epoch  4  train_acc  0.3479  val_acc  0.3484\n",
      "epoch  5  train_acc  0.39332  val_acc  0.3946\n",
      "epoch  6  train_acc  0.43254  val_acc  0.4372\n",
      "epoch  7  train_acc  0.46458  val_acc  0.4708\n",
      "epoch  8  train_acc  0.49286  val_acc  0.4959\n",
      "epoch  9  train_acc  0.51142  val_acc  0.5162\n",
      " test_acc  0.5239\n",
      "total time  51.98349118232727 seconds\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "Y = y_train\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "iters = (X.shape[0] - 1)//batch_size + 1\n",
    "tr_loss_list = []\n",
    "test_loss_list = []\n",
    "time_start = time.time()\n",
    "lr = 0.001\n",
    "with tf.Session(graph=g) as sess:\n",
    "#-------training part--------------\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        X,Y = shuffle(X,Y)\n",
    "        if e==5:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "            lr = lr *0.9\n",
    "        if e>5:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "            lr = lr*0.9\n",
    "        for j in range(iters):\n",
    "            batch_x = X[j * batch_size:(j + 1) * batch_size,:]\n",
    "            batch_y = Y[j * batch_size:(j + 1) * batch_size]\n",
    "            _,batch_loss = sess.run([optimizer,loss],feed_dict={input_x:batch_x,input_y:batch_y})\n",
    "           \n",
    "        \n",
    "        pred_tr_y = sess.run(preds,{input_x:X_train,})\n",
    "        pred_val_y = sess.run(preds,{input_x:X_val})\n",
    "        tr_acc = accuracy_score(y_train,pred_tr_y)\n",
    "        val_acc = accuracy_score(y_val,pred_val_y)\n",
    "        print(\"epoch \",e,\" train_acc \",tr_acc,\" val_acc \",val_acc)\n",
    "        \n",
    "        tr_loss_list.append(sess.run(loss,{input_x:X_train,input_y:y_train}))\n",
    "        \n",
    "        test_loss_list.append(sess.run(loss,{input_x:X_test,input_y:y_test}))\n",
    "\n",
    "#----------------------evaluation part----------------\n",
    "    pred_test_y = sess.run(preds,{input_x:X_test})\n",
    "    test_acc = accuracy_score(y_test,pred_test_y)\n",
    "    print(\" test_acc \",test_acc)\n",
    "        \n",
    "print(\"total time \",time.time()-time_start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 40\n",
    "\n",
    "# for logging the progress right here in Jupyter (for those who don't have TensorBoard)\n",
    "simpleTrainingCurves = matplotlib_utils.SimpleTrainingCurves(\"cross-entropy\", \"accuracy\")\n",
    "\n",
    "for epoch in range(EPOCHS):  # we finish an epoch when we've looked at all training samples\n",
    "    \n",
    "    batch_losses = []\n",
    "    for batch_start in range(0, X_train_flat.shape[0], BATCH_SIZE):  # data is already shuffled\n",
    "        _, batch_loss = s.run([step, loss], {input_X: X_train_flat[batch_start:batch_start+BATCH_SIZE], \n",
    "                                             input_y: y_train_oh[batch_start:batch_start+BATCH_SIZE]})\n",
    "        # collect batch losses, this is almost free as we need a forward pass for backprop anyway\n",
    "        batch_losses.append(batch_loss)\n",
    "\n",
    "    train_loss = np.mean(batch_losses)\n",
    "    val_loss = s.run(loss, {input_X: X_val_flat, input_y: y_val_oh})  # this part is usually small\n",
    "    train_accuracy = accuracy_score(y_train, s.run(classes, {input_X: X_train_flat}))  # this is slow and usually skipped\n",
    "    valid_accuracy = accuracy_score(y_val, s.run(classes, {input_X: X_val_flat}))  \n",
    "    simpleTrainingCurves.add(train_loss, val_loss, train_accuracy, valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e8bf398f9c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"9XaAS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrading_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensors_shapes_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vmogZ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_val_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_val_oh\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgrader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMv95\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_X\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_val_flat\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "# Testing shapes \n",
    "grader.set_answer(\"9XaAS\", grading_utils.get_tensors_shapes_string([w1, b1, input_x, input_y, logits, probs, preds]))\n",
    "# Validation loss\n",
    "grader.set_answer(\"vmogZ\", sess.run(loss, {input_x: X_val_flat, input_y: y_val_oh}))\n",
    "# Validation accuracy\n",
    "grader.set_answer(\"RMv95\", accuracy_score(y_val, s.run(classes, {input_X: X_val_flat})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we've coded a dense layer with matrix multiplication by hand. \n",
    "But this is not convenient, you have to create a lot of variables and your code becomes a mess. \n",
    "In TensorFlow there's an easier way to make a dense layer:\n",
    "```python\n",
    "hidden1 = tf.layers.dense(inputs, 256, activation=tf.nn.sigmoid)\n",
    "```\n",
    "\n",
    "That will create all the necessary variables automatically.\n",
    "Here you can also choose an activation function (remember that we need it for a hidden layer!).\n",
    "\n",
    "Now define the MLP with 2 hidden layers and restart training with the cell above.\n",
    "\n",
    "You're aiming for ~0.97 validation accuracy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the code here to get a new `step` operation and then run the cell with training loop above.\n",
    "# name your variables in the same way (e.g. logits, probas, classes, etc) for safety.\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit the MLP with 2 hidden layers\n",
    "Run these cells after training the MLP with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "# Validation loss for MLP\n",
    "grader.set_answer(\"i8bgs\", s.run(loss, {input_X: X_val_flat, input_y: y_val_oh}))\n",
    "# Validation accuracy for MLP\n",
    "grader.set_answer(\"rE763\", accuracy_score(y_val, s.run(classes, {input_X: X_val_flat})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
